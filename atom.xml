<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一只空小白</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-05-14T04:12:23.256Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Scrapy爬虫框架安装与使用，数据存Mongdb，Mysql数据库</title>
    <link href="http://example.com/2024/05/14/Scrapy%E7%88%AC%E8%99%AB/"/>
    <id>http://example.com/2024/05/14/Scrapy%E7%88%AC%E8%99%AB/</id>
    <published>2024-05-14T03:48:15.000Z</published>
    <updated>2024-05-14T04:12:23.256Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Scrapy爬虫框架安装与使用，数据存Mongdb，Mysql数据库"><a href="#Scrapy爬虫框架安装与使用，数据存Mongdb，Mysql数据库" class="headerlink" title="Scrapy爬虫框架安装与使用，数据存Mongdb，Mysql数据库"></a>Scrapy爬虫框架安装与使用，数据存Mongdb，Mysql数据库</h1><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><h2 id="环境搭建"><a href="#环境搭建" class="headerlink" title="环境搭建"></a>环境搭建</h2><p>python环境3.10<br>所需库 mongodb,mysql,scrapy</p><p>pip临时使用清华源，下载速度更快</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple mongodb</span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple mysql</span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple scrap</span><br></pre></td></tr></table></figure><p><img src="/../images/scrapy/img_1.png" class="lazyload placeholder" data-srcset="/../images/scrapy/img_1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="alt text" title="Title"></p><h2 id="搭建框架"><a href="#搭建框架" class="headerlink" title="搭建框架"></a>搭建框架</h2><p>新建一个目录存放Scrap爬虫框架，进入到到该目录下，使用命令创建框架</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject pc7k7k #Scrap创建框架</span><br><span class="line">cd pc7k7k  #进入到目录</span><br><span class="line">scrapy genspider pc_7k7k 7k7k.com  #pc_7k7k爬虫文件名（不可以与目录名相同），7k7k.com是要爬的网站（后续可以改）</span><br></pre></td></tr></table></figure><p><img src="/../images/scrapy/img.png" class="lazyload placeholder" data-srcset="/../images/scrapy/img.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="alt text" title="Title"></p><h2 id="目录结构"><a href="#目录结构" class="headerlink" title="目录结构"></a>目录结构</h2><p><img src="/../images/scrapy/img_2.png" class="lazyload placeholder" data-srcset="/../images/scrapy/img_2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="alt text" title="Title"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg ：  项目的配置文件</span><br><span class="line">items.py ：    项目的目标文件</span><br><span class="line">pipelines.py ：项目的管道文件</span><br><span class="line">settings.py ： 项目的设置文件</span><br><span class="line">spiders ：     存储爬虫代码目录</span><br></pre></td></tr></table></figure><h3 id="pc-7k7k-py："><a href="#pc-7k7k-py：" class="headerlink" title="pc_7k7k.py："></a>pc_7k7k.py：</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">from ..items import PachongItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Pachong1Spider(scrapy.Spider):</span><br><span class="line">    name = &quot;pachong_1&quot;</span><br><span class="line">    allowed_domains = [&quot;jntc.nm.cn&quot;]</span><br><span class="line">    start_urls = [&quot;http://www.jntc.nm.cn/news/zhxw.htm&quot;]  #综合新闻</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # 创建一个PachongItem实例来存储提取的数据</span><br><span class="line">        item = PachongItem()</span><br><span class="line">        item[&#x27;rq&#x27;] = response.xpath(&#x27;//ul//span/text()&#x27;).extract()</span><br><span class="line">        item[&#x27;bt&#x27;] = response.xpath(&#x27;//div[@class=&quot;pg-list fr list-right-cont&quot;]//ul//a[@target=&quot;_blank&quot;]/text()&#x27;).extract()</span><br><span class="line">        yield item</span><br><span class="line"></span><br><span class="line">        # 查找下一页的链接</span><br><span class="line">        next_page = response.xpath(&#x27;//a[@href and contains(text(), &quot;下页&quot;)]/@href&#x27;).get()</span><br><span class="line">        if next_page:</span><br><span class="line">            next_page_url = response.urljoin(next_page)</span><br><span class="line">            yield scrapy.Request(next_page_url, callback=self.parse)  # 递归调用parse来处理下一页</span><br></pre></td></tr></table></figure><h3 id="items-py"><a href="#items-py" class="headerlink" title="items.py:"></a>items.py:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class PachongItem(scrapy.Item):</span><br><span class="line">    _id = scrapy.Field()</span><br><span class="line">    rq = scrapy.Field()</span><br><span class="line">    bt = scrapy.Field()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py:"></a>pipelines.py:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import pymongo</span><br><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line">#存Mongodb</span><br><span class="line">class MongodbPipeline:</span><br><span class="line"></span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        self.client = pymongo.MongoClient(host=&quot;127.0.0.1&quot;,port=27017)</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        self.client.jnsf.sj.insert_one(item)</span><br><span class="line">        return item</span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.client.close()</span><br><span class="line"></span><br><span class="line">#存Mysql</span><br><span class="line">class MysqlPipeline:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.conn = pymysql.connect(host=&#x27;localhost&#x27;, user=&#x27;root&#x27;, password=&#x27;123456789&#x27;, db=&#x27;jnsf&#x27;,charset=&#x27;utf8mb4&#x27;)</span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line">        # 检查表是否存在，如果不存在则创建它</span><br><span class="line">        self.create_table_if_not_exists()</span><br><span class="line">    def create_table_if_not_exists(self):</span><br><span class="line">        create_table_sql = &#x27;&#x27;&#x27;  </span><br><span class="line">        CREATE TABLE IF NOT EXISTS jnsf_table (  </span><br><span class="line">            id INT AUTO_INCREMENT PRIMARY KEY,  </span><br><span class="line">            Publication_date VARCHAR(1000) NOT NULL,  </span><br><span class="line">            title VARCHAR(1000) NOT NULL  </span><br><span class="line">        )  </span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        try:</span><br><span class="line">            self.cursor.execute(create_table_sql)</span><br><span class="line">            self.conn.commit()</span><br><span class="line">            print(&quot;创建成功&quot;)</span><br><span class="line">        except pymysql.MySQLError as e:</span><br><span class="line">            print(f&quot;创建失败 &#123;e&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        insert_sql = &#x27;INSERT INTO jnsf_table(Publication_date, title) VALUES (%s, %s)&#x27;</span><br><span class="line">        for i, title in enumerate(item[&#x27;bt&#x27;]):</span><br><span class="line">            self.cursor.execute(insert_sql, (item[&#x27;rq&#x27;][i], item[&#x27;bt&#x27;][i]))</span><br><span class="line">        self.conn.commit()</span><br><span class="line">        return item</span><br><span class="line"></span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.cursor.close()</span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure><h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py:"></a>settings.py:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = False  </span><br><span class="line">DOWNLOAD_DELAY = 1</span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   &quot;pachong.pipelines.MongodbPipeline&quot;: 300,</span><br><span class="line">   &quot;pachong.pipelines.MysqlPipeline&quot;: 400,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="运行爬虫"><a href="#运行爬虫" class="headerlink" title="运行爬虫"></a>运行爬虫</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl pachong_1     # pachong_1爬虫的名字</span><br></pre></td></tr></table></figure><h2 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Scrapy爬虫框架安装与使用，数据存Mongdb，Mysql数据库&quot;&gt;&lt;a href=&quot;#Scrapy爬虫框架安装与使用，数据存Mongdb，Mysql数据库&quot; class=&quot;headerlink&quot; title=&quot;Scrapy爬虫框架安装与使用，数据存Mongd</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://example.com/2024/05/13/hello-world/"/>
    <id>http://example.com/2024/05/13/hello-world/</id>
    <published>2024-05-13T13:33:01.323Z</published>
    <updated>2024-05-13T13:33:01.323Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for</summary>
      
    
    
    
    
  </entry>
  
</feed>
