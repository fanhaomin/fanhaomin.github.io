<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>ä¸€åªç©ºå°ç™½ğŸ’«</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-05-14T12:54:21.764Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ</title>
    <link href="http://example.com/2024/05/14/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/"/>
    <id>http://example.com/2024/05/14/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/</id>
    <published>2024-05-14T12:05:10.102Z</published>
    <updated>2024-05-14T12:54:21.764Z</updated>
    
    <content type="html"><![CDATA[<h1 id="æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ"><a href="#æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ" class="headerlink" title="æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ"></a>æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ</h1><h1 id="è¦æ±‚"><a href="#è¦æ±‚" class="headerlink" title="è¦æ±‚"></a>è¦æ±‚</h1><p>äº”ä¸ªå°å®éªŒæ–‡æ¡£æäº¤-å‰å››ä¸ªä¸ªäººä½œä¸šï¼Œç¬¬äº”ä¸ªå°ç»„ä½œä¸šã€‚éœ€æäº¤é…å¥—æ–‡æ¡£ï¼Œæ–‡æ¡£æ¨¡æ¿å¦‚ä¸‹ï¼‰<br>1.ç™¾åº¦æ–°é—»çš„çˆ¬å–&amp;è‡ªç”±æ‰©å±•çˆ¬å–<br>2.bs4é‡æ–°çˆ¬å–ç™¾åº¦æ–°é—»<br>3.é£å¢å°è¯´ç½‘çˆ¬å–ä¸å­˜å‚¨æ•°æ®åº“<br>4.è®¾è®¡ä¸€ä¸ªæ•°æ®åº“ç³»ç»Ÿï¼Œè¦æ±‚è‡³å°‘5å¼ è¡¨ä»¥ä¸Šï¼Œç”¨workbenchä½œå›¾ï¼Œå±æ€§å®Œæ•´ï¼Œå¿…è¦çš„è¿æ¥å®Œæ•´<br>5.Pyspiderçš„å®‰è£…ä¸è¿è¡Œ</p><p>å®éªŒæŠ¥å‘Šä¸‹è½½åœ°å€: <a href="https://pan.baidu.com/s/1BSYLksyIBvvHSUHW3SJ31w?pwd=kbcx">ç™¾åº¦ç½‘ç›˜</a></p><h2 id="1-ç™¾åº¦æ–°é—»çš„çˆ¬å–-è‡ªç”±æ‰©å±•çˆ¬å–"><a href="#1-ç™¾åº¦æ–°é—»çš„çˆ¬å–-è‡ªç”±æ‰©å±•çˆ¬å–" class="headerlink" title="1.ç™¾åº¦æ–°é—»çš„çˆ¬å–&amp;è‡ªç”±æ‰©å±•çˆ¬å–"></a>1.ç™¾åº¦æ–°é—»çš„çˆ¬å–&amp;è‡ªç”±æ‰©å±•çˆ¬å–</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># å¯¼å…¥éœ€è¦çš„æ¨¡å—</span></span><br><span class="line"><span class="keyword">import</span> urllib.request  <span class="comment"># ç”¨äºä»URLè·å–æ•°æ®</span></span><br><span class="line"><span class="keyword">import</span> re  <span class="comment"># ç”¨äºæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…</span></span><br><span class="line"><span class="keyword">import</span> datetime  <span class="comment"># ç”¨äºå¤„ç†æ—¥æœŸå’Œæ—¶é—´</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰ä¸¤ä¸ªURLï¼Œåˆ†åˆ«å¯¹åº”æ–°é—»å’Œè§†é¢‘ç½‘ç«™</span></span><br><span class="line">url1 = <span class="string">&#x27;https://news.baidu.com/&#x27;</span></span><br><span class="line">url2 = <span class="string">&#x27;https://v.xiaodutv.com/&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨urllib.requestæ¨¡å—ä»URLä¸­è·å–å†…å®¹ï¼Œå¹¶è§£ç ä¸ºutf-8æ ¼å¼</span></span><br><span class="line">content1 = urllib.request.urlopen(url1).read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line">content2 = urllib.request.urlopen(url2).read().decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰ä¸¤ä¸ªæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼Œç”¨äºåŒ¹é…æ–°é—»å’Œè§†é¢‘ç½‘ç«™çš„ç‰¹å®šå†…å®¹</span></span><br><span class="line"><span class="comment"># pattern1ç”¨äºåŒ¹é…æ–°é—»ç½‘ç«™çš„çƒ­ç‚¹æ–°é—»æ ‡é¢˜</span></span><br><span class="line">pattern1 = re.<span class="built_in">compile</span>(<span class="string">&#x27;&lt;li class=&quot;hdline.*?&lt;strong&gt;.*?&lt;a.*?&gt;(.*?)&lt;/a&gt;.*?strong&gt;&#x27;</span>, re.S)</span><br><span class="line"><span class="comment"># pattern2ç”¨äºåŒ¹é…è§†é¢‘ç½‘ç«™çš„çƒ­ç‚¹è§†é¢‘æ ‡é¢˜</span></span><br><span class="line">pattern2 = re.<span class="built_in">compile</span>(<span class="string">&quot;&lt;li class=&#x27;poste.*?&lt;a.*?&lt;img.*?&lt;p.*?&gt;(.*?)&lt;/p&gt;&quot;</span>, re.S)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ä»å†…å®¹ä¸­æå–åŒ¹é…çš„ä¿¡æ¯</span></span><br><span class="line">hotNews1 = re.findall(pattern1, content1)</span><br><span class="line">hotNews2 = re.findall(pattern2, content2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ‰“å°æå–çš„çƒ­ç‚¹æ–°é—»</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> hotNews1:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;çƒ­ç‚¹æ–°é—»ï¼š&quot;</span>, i)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="comment"># æ‰“å°æå–çš„çƒ­ç‚¹è§†é¢‘</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> hotNews2:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;çƒ­ç‚¹è§†é¢‘:&quot;</span>, i)</span><br><span class="line"><span class="comment"># æ‰“å°å½“å‰çš„æ—¶é—´</span></span><br><span class="line"><span class="built_in">print</span>(datetime.datetime.now())</span><br></pre></td></tr></table></figure><h2 id="bs4é‡æ–°çˆ¬å–ç™¾åº¦æ–°é—»"><a href="#bs4é‡æ–°çˆ¬å–ç™¾åº¦æ–°é—»" class="headerlink" title="bs4é‡æ–°çˆ¬å–ç™¾åº¦æ–°é—»"></a>bs4é‡æ–°çˆ¬å–ç™¾åº¦æ–°é—»</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup  <span class="comment"># å¯¼å…¥BeautifulSoupåº“ï¼Œç”¨äºè§£æHTMLå†…å®¹</span></span><br><span class="line"><span class="keyword">import</span> requests  <span class="comment"># å¯¼å…¥requestsåº“ï¼Œç”¨äºå‘é€HTTPè¯·æ±‚</span></span><br><span class="line"></span><br><span class="line">url = <span class="string">&#x27;https://news.baidu.com&#x27;</span>  <span class="comment"># å®šä¹‰è¦çˆ¬å–çš„ç½‘é¡µURL</span></span><br><span class="line"><span class="comment"># ä½¿ç”¨requestsåº“å‘é€GETè¯·æ±‚ï¼Œè·å–ç½‘é¡µå†…å®¹</span></span><br><span class="line">res = requests.get(url)</span><br><span class="line"><span class="comment"># ä½¿ç”¨BeautifulSoupè§£æç½‘é¡µå†…å®¹</span></span><br><span class="line">soup = BeautifulSoup(res.text, <span class="string">&#x27;lxml&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># å®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œç”¨äºç§»é™¤å­—ç¬¦ä¸²ä¸­çš„ç©ºè¡Œ</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">remove_empty_lines</span>(<span class="params">s</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&#x27;\n&#x27;</span>.join([line <span class="keyword">for</span> line <span class="keyword">in</span> s.splitlines() <span class="keyword">if</span> line.strip()])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;çƒ­ç‚¹æ–°é—»ï¼š\n&#x27;</span>)  <span class="comment"># æ‰“å°æ ‡é¢˜ï¼Œè¡¨ç¤ºæ¥ä¸‹æ¥è¾“å‡ºçš„æ˜¯çƒ­ç‚¹æ–°é—»</span></span><br><span class="line"><span class="comment"># å¾ªç¯6æ¬¡ï¼Œå°è¯•æŸ¥æ‰¾ä¸åŒç±»åçš„çƒ­ç‚¹æ–°é—»</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    news_list = soup.find_all(class_=<span class="string">&#x27;hdline&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(i))  <span class="comment"># ä½¿ç”¨find_allæ–¹æ³•æŸ¥æ‰¾ç±»åä¸º&#x27;hdline0&#x27;åˆ°&#x27;hdline5&#x27;çš„å…ƒç´ </span></span><br><span class="line">    <span class="keyword">for</span> news <span class="keyword">in</span> news_list:  <span class="comment"># éå†æ‰¾åˆ°çš„æ‰€æœ‰æ–°é—»å…ƒç´ </span></span><br><span class="line">        <span class="built_in">print</span>(remove_empty_lines(news.get_text()))  <span class="comment"># æ‰“å°æ–°é—»å†…å®¹ï¼Œå¹¶ç§»é™¤ç©ºè¡Œ</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;\nå…¶ä»–æ–°é—»ï¼š\n&#x27;</span>)  <span class="comment"># æ‰“å°æ ‡é¢˜ï¼Œè¡¨ç¤ºæ¥ä¸‹æ¥è¾“å‡ºçš„æ˜¯å…¶ä»–æ–°é—»</span></span><br><span class="line"><span class="comment"># æŸ¥æ‰¾ç±»åä¸º&#x27;ulist focuslistnews&#x27;çš„å…ƒç´ ï¼Œè¿™äº›å…ƒç´ é€šå¸¸åŒ…å«å…¶ä»–æ–°é—»</span></span><br><span class="line">news_list1 = soup.find_all(class_=<span class="string">&#x27;ulist focuslistnews&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> news <span class="keyword">in</span> news_list1:  <span class="comment"># éå†æ‰¾åˆ°çš„æ‰€æœ‰å…¶ä»–æ–°é—»å…ƒç´ </span></span><br><span class="line">    <span class="built_in">print</span>(remove_empty_lines(news.get_text()))  <span class="comment"># æ‰“å°æ–°é—»å†…å®¹ï¼Œå¹¶ç§»é™¤ç©ºè¡Œ</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;çƒ­æœæ–°é—»è¯ï¼š\n&#x27;</span>)  <span class="comment"># æ‰“å°æ ‡é¢˜ï¼Œè¡¨ç¤ºæ¥ä¸‹æ¥è¾“å‡ºçš„æ˜¯çƒ­æœæ–°é—»è¯</span></span><br><span class="line"><span class="comment"># æŸ¥æ‰¾ç±»åä¸º&#x27;bd&#x27;çš„å…ƒç´ ï¼Œè¿™äº›å…ƒç´ é€šå¸¸åŒ…å«çƒ­æœæ–°é—»è¯</span></span><br><span class="line">news_list2 = soup.find_all(class_=<span class="string">&#x27;bd&#x27;</span>)</span><br><span class="line"><span class="keyword">for</span> news <span class="keyword">in</span> news_list2:  <span class="comment"># éå†æ‰¾åˆ°çš„æ‰€æœ‰çƒ­æœæ–°é—»è¯å…ƒç´ </span></span><br><span class="line">    <span class="built_in">print</span>(remove_empty_lines(news.get_text()))  <span class="comment"># æ‰“å°çƒ­æœæ–°é—»è¯å†…å®¹ï¼Œå¹¶ç§»é™¤ç©ºè¡Œ</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="å¢å°è¯´ç½‘çˆ¬å–ä¸å­˜å‚¨æ•°æ®åº“"><a href="#å¢å°è¯´ç½‘çˆ¬å–ä¸å­˜å‚¨æ•°æ®åº“" class="headerlink" title="å¢å°è¯´ç½‘çˆ¬å–ä¸å­˜å‚¨æ•°æ®åº“"></a>å¢å°è¯´ç½‘çˆ¬å–ä¸å­˜å‚¨æ•°æ®åº“</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> pymysql</span><br><span class="line"></span><br><span class="line"><span class="comment">#10æœ¬å°è¯´ç½‘å€</span></span><br><span class="line">url = [ <span class="string">&#x27;https://b.faloo.com/1409514.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1406411.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1378270.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1406675.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1408380.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1236995.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1405654.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1376693.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/1410749.html&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;https://b.faloo.com/671060.html&#x27;</span></span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">db = pymysql.connect(</span><br><span class="line">    host=<span class="string">&#x27;127.0.0.1&#x27;</span>,      <span class="comment"># å¤–ç½‘/å†…ç½‘åœ°å€</span></span><br><span class="line">    user=<span class="string">&#x27;root&#x27;</span>,           <span class="comment"># è´¦å·</span></span><br><span class="line">    password=<span class="string">&#x27;123456789&#x27;</span>,  <span class="comment"># å¯†ç </span></span><br><span class="line">    db=<span class="string">&#x27;xiaoshuo&#x27;</span>,         <span class="comment"># databaseåç§°</span></span><br><span class="line">    charset=<span class="string">&#x27;utf8&#x27;</span>         <span class="comment"># ç¼–ç æ ¼å¼</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># æ‹¿åˆ°æ¸¸æ ‡</span></span><br><span class="line">cursor = db.cursor()</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_url</span>(<span class="params">url</span>):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        response = requests.get(url)</span><br><span class="line">        response.raise_for_status()</span><br><span class="line">        soup = BeautifulSoup(response.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">        Topic = soup.find(<span class="string">&#x27;h1&#x27;</span>, class_=<span class="string">&#x27;fs23&#x27;</span>).text</span><br><span class="line">        divs = soup.find_all(<span class="string">&#x27;div&#x27;</span>, class_=<span class="string">&#x27;DivTd3&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> divs, Topic</span><br><span class="line">    <span class="keyword">except</span> requests.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;è·å–ç½‘é¡µé”™è¯¯ï¼š<span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> []</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_content</span>(<span class="params">divs, path, a</span>):</span><br><span class="line">        <span class="keyword">for</span> div <span class="keyword">in</span> divs:</span><br><span class="line">            url = <span class="string">&#x27;https:&#x27;</span> + div.a[<span class="string">&#x27;href&#x27;</span>]</span><br><span class="line">            chapter_name = div.text</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                rq = requests.get(url)</span><br><span class="line">                rq.raise_for_status()</span><br><span class="line">                soup1 = BeautifulSoup(rq.text, <span class="string">&#x27;html.parser&#x27;</span>)</span><br><span class="line">                chapter_content = soup1.find(name=<span class="string">&#x27;div&#x27;</span>, class_=a).text</span><br><span class="line">                <span class="comment"># å­˜åˆ°æ•°æ®åº“</span></span><br><span class="line">                sql = <span class="string">&quot;INSERT INTO xiao_shuo (ä¹¦å,ç« èŠ‚,å†…å®¹) VALUES (%s,%s,%s)&quot;</span></span><br><span class="line">                val = (path, chapter_name, chapter_content)  <span class="comment"># è¿™é‡Œæ›¿æ¢ä¸ºä½ è¦æ’å…¥çš„å®é™…å€¼</span></span><br><span class="line">                cursor.execute(sql, val)</span><br><span class="line">                db.commit()</span><br><span class="line">            <span class="keyword">except</span> requests.HTTPError <span class="keyword">as</span> e:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;è®¿é—®ç« èŠ‚é¡µé¢å¤±è´¥ï¼š&#x27;<span class="subst">&#123;e&#125;</span>&#x27;&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;path&#125;</span>------------------å…¨éƒ¨ç« èŠ‚å·²ä¸‹è½½åˆ°æ•°æ®åº“ï¼&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    url1, Topic = get_url(url[i])</span><br><span class="line">    get_content(url1, Topic, <span class="string">&#x27;noveContent&#x27;</span>)</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ&quot;&gt;&lt;a href=&quot;#æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ&quot; class=&quot;headerlink&quot; title=&quot;æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ&quot;&gt;&lt;/a&gt;æ•°æ®é‡‡é›†ä¸é¢„å¤„ç†å®éªŒ&lt;/h1&gt;&lt;h1 id=&quot;è¦æ±‚&quot;&gt;&lt;a href=&quot;#è¦æ±‚&quot; class=&quot;headerli</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongdbï¼ŒMysqlæ•°æ®åº“</title>
    <link href="http://example.com/2024/05/14/Scrapy%E7%88%AC%E8%99%AB/"/>
    <id>http://example.com/2024/05/14/Scrapy%E7%88%AC%E8%99%AB/</id>
    <published>2024-05-14T03:48:15.000Z</published>
    <updated>2024-05-14T04:16:22.181Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongdbï¼ŒMysqlæ•°æ®åº“"><a href="#Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongdbï¼ŒMysqlæ•°æ®åº“" class="headerlink" title="Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongdbï¼ŒMysqlæ•°æ®åº“"></a>Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongdbï¼ŒMysqlæ•°æ®åº“</h1><h2 id="å¼€å§‹"><a href="#å¼€å§‹" class="headerlink" title="å¼€å§‹"></a>å¼€å§‹</h2><h2 id="ç¯å¢ƒæ­å»º"><a href="#ç¯å¢ƒæ­å»º" class="headerlink" title="ç¯å¢ƒæ­å»º"></a>ç¯å¢ƒæ­å»º</h2><p>pythonç¯å¢ƒ3.10<br>æ‰€éœ€åº“ mongodb,mysql,scrapy</p><p>pipä¸´æ—¶ä½¿ç”¨æ¸…åæºï¼Œä¸‹è½½é€Ÿåº¦æ›´å¿«</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple mongodb</span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple mysql</span><br><span class="line">pip install -i https://pypi.tuna.tsinghua.edu.cn/simple scrap</span><br></pre></td></tr></table></figure><p><img src="/../images/scrapy/img_1.png" class="lazyload placeholder" data-srcset="/../images/scrapy/img_1.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="alt text" title="Title"></p><h2 id="æ­å»ºæ¡†æ¶"><a href="#æ­å»ºæ¡†æ¶" class="headerlink" title="æ­å»ºæ¡†æ¶"></a>æ­å»ºæ¡†æ¶</h2><p>æ–°å»ºä¸€ä¸ªç›®å½•å­˜æ”¾Scrapçˆ¬è™«æ¡†æ¶ï¼Œè¿›å…¥åˆ°åˆ°è¯¥ç›®å½•ä¸‹ï¼Œä½¿ç”¨å‘½ä»¤åˆ›å»ºæ¡†æ¶</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject pc7k7k #Scrapåˆ›å»ºæ¡†æ¶</span><br><span class="line">cd pc7k7k  #è¿›å…¥åˆ°ç›®å½•</span><br><span class="line">scrapy genspider pc_7k7k 7k7k.com  #pc_7k7kçˆ¬è™«æ–‡ä»¶åï¼ˆä¸å¯ä»¥ä¸ç›®å½•åç›¸åŒï¼‰ï¼Œ7k7k.comæ˜¯è¦çˆ¬çš„ç½‘ç«™ï¼ˆåç»­å¯ä»¥æ”¹ï¼‰</span><br></pre></td></tr></table></figure><p><img src="/../images/scrapy/img.png" class="lazyload placeholder" data-srcset="/../images/scrapy/img.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="alt text" title="Title"></p><h2 id="ç›®å½•ç»“æ„"><a href="#ç›®å½•ç»“æ„" class="headerlink" title="ç›®å½•ç»“æ„"></a>ç›®å½•ç»“æ„</h2><p><img src="/../images/scrapy/img_2.png" class="lazyload placeholder" data-srcset="/../images/scrapy/img_2.png" srcset="https://pic1.zhimg.com/v2-cd38920285d125be80b3eb504052c550_b.webp" alt="alt text" title="Title"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg ï¼š  é¡¹ç›®çš„é…ç½®æ–‡ä»¶</span><br><span class="line">items.py ï¼š    é¡¹ç›®çš„ç›®æ ‡æ–‡ä»¶</span><br><span class="line">pipelines.py ï¼šé¡¹ç›®çš„ç®¡é“æ–‡ä»¶</span><br><span class="line">settings.py ï¼š é¡¹ç›®çš„è®¾ç½®æ–‡ä»¶</span><br><span class="line">spiders ï¼š     å­˜å‚¨çˆ¬è™«ä»£ç ç›®å½•</span><br></pre></td></tr></table></figure><h3 id="pc-7k7k-pyï¼š"><a href="#pc-7k7k-pyï¼š" class="headerlink" title="pc_7k7k.pyï¼š"></a>pc_7k7k.pyï¼š</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line">from ..items import PachongItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Pachong1Spider(scrapy.Spider):</span><br><span class="line">    name = &quot;pachong_1&quot;</span><br><span class="line">    allowed_domains = [&quot;jntc.nm.cn&quot;]</span><br><span class="line">    start_urls = [&quot;http://www.jntc.nm.cn/news/zhxw.htm&quot;]  #ç»¼åˆæ–°é—»</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        # åˆ›å»ºä¸€ä¸ªPachongItemå®ä¾‹æ¥å­˜å‚¨æå–çš„æ•°æ®</span><br><span class="line">        item = PachongItem()</span><br><span class="line">        item[&#x27;rq&#x27;] = response.xpath(&#x27;//ul//span/text()&#x27;).extract()</span><br><span class="line">        item[&#x27;bt&#x27;] = response.xpath(&#x27;//div[@class=&quot;pg-list fr list-right-cont&quot;]//ul//a[@target=&quot;_blank&quot;]/text()&#x27;).extract()</span><br><span class="line">        yield item</span><br><span class="line"></span><br><span class="line">        # æŸ¥æ‰¾ä¸‹ä¸€é¡µçš„é“¾æ¥</span><br><span class="line">        next_page = response.xpath(&#x27;//a[@href and contains(text(), &quot;ä¸‹é¡µ&quot;)]/@href&#x27;).get()</span><br><span class="line">        if next_page:</span><br><span class="line">            next_page_url = response.urljoin(next_page)</span><br><span class="line">            yield scrapy.Request(next_page_url, callback=self.parse)  # é€’å½’è°ƒç”¨parseæ¥å¤„ç†ä¸‹ä¸€é¡µ</span><br></pre></td></tr></table></figure><h3 id="items-py"><a href="#items-py" class="headerlink" title="items.py:"></a>items.py:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line">class PachongItem(scrapy.Item):</span><br><span class="line">    _id = scrapy.Field()</span><br><span class="line">    rq = scrapy.Field()</span><br><span class="line">    bt = scrapy.Field()</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="pipelines-py"><a href="#pipelines-py" class="headerlink" title="pipelines.py:"></a>pipelines.py:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line">import pymongo</span><br><span class="line">import pymysql</span><br><span class="line"></span><br><span class="line">#å­˜Mongodb</span><br><span class="line">class MongodbPipeline:</span><br><span class="line"></span><br><span class="line">    def open_spider(self, spider):</span><br><span class="line">        self.client = pymongo.MongoClient(host=&quot;127.0.0.1&quot;,port=27017)</span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        self.client.jnsf.sj.insert_one(item)</span><br><span class="line">        return item</span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.client.close()</span><br><span class="line"></span><br><span class="line">#å­˜Mysql</span><br><span class="line">class MysqlPipeline:</span><br><span class="line">    def __init__(self):</span><br><span class="line">        self.conn = pymysql.connect(host=&#x27;localhost&#x27;, user=&#x27;root&#x27;, password=&#x27;123456789&#x27;, db=&#x27;jnsf&#x27;,charset=&#x27;utf8mb4&#x27;)</span><br><span class="line">        self.cursor = self.conn.cursor()</span><br><span class="line">        # æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»ºå®ƒ</span><br><span class="line">        self.create_table_if_not_exists()</span><br><span class="line">    def create_table_if_not_exists(self):</span><br><span class="line">        create_table_sql = &#x27;&#x27;&#x27;  </span><br><span class="line">        CREATE TABLE IF NOT EXISTS jnsf_table (  </span><br><span class="line">            id INT AUTO_INCREMENT PRIMARY KEY,  </span><br><span class="line">            Publication_date VARCHAR(1000) NOT NULL,  </span><br><span class="line">            title VARCHAR(1000) NOT NULL  </span><br><span class="line">        )  </span><br><span class="line">        &#x27;&#x27;&#x27;</span><br><span class="line">        try:</span><br><span class="line">            self.cursor.execute(create_table_sql)</span><br><span class="line">            self.conn.commit()</span><br><span class="line">            print(&quot;åˆ›å»ºæˆåŠŸ&quot;)</span><br><span class="line">        except pymysql.MySQLError as e:</span><br><span class="line">            print(f&quot;åˆ›å»ºå¤±è´¥ &#123;e&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    def process_item(self, item, spider):</span><br><span class="line">        insert_sql = &#x27;INSERT INTO jnsf_table(Publication_date, title) VALUES (%s, %s)&#x27;</span><br><span class="line">        for i, title in enumerate(item[&#x27;bt&#x27;]):</span><br><span class="line">            self.cursor.execute(insert_sql, (item[&#x27;rq&#x27;][i], item[&#x27;bt&#x27;][i]))</span><br><span class="line">        self.conn.commit()</span><br><span class="line">        return item</span><br><span class="line"></span><br><span class="line">    def close_spider(self, spider):</span><br><span class="line">        self.cursor.close()</span><br><span class="line">        self.conn.close()</span><br></pre></td></tr></table></figure><h3 id="settings-py"><a href="#settings-py" class="headerlink" title="settings.py:"></a>settings.py:</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ROBOTSTXT_OBEY = False  </span><br><span class="line">DOWNLOAD_DELAY = 1</span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   &quot;pachong.pipelines.MongodbPipeline&quot;: 300,</span><br><span class="line">   &quot;pachong.pipelines.MysqlPipeline&quot;: 400,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="è¿è¡Œçˆ¬è™«"><a href="#è¿è¡Œçˆ¬è™«" class="headerlink" title="è¿è¡Œçˆ¬è™«"></a>è¿è¡Œçˆ¬è™«</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl pachong_1     # pachong_1çˆ¬è™«çš„åå­—</span><br></pre></td></tr></table></figure><h2 id="ç»“æŸ"><a href="#ç»“æŸ" class="headerlink" title="ç»“æŸ"></a>ç»“æŸ</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongdbï¼ŒMysqlæ•°æ®åº“&quot;&gt;&lt;a href=&quot;#Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongdbï¼ŒMysqlæ•°æ®åº“&quot; class=&quot;headerlink&quot; title=&quot;Scrapyçˆ¬è™«æ¡†æ¶å®‰è£…ä¸ä½¿ç”¨ï¼Œæ•°æ®å­˜Mongd</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://example.com/2024/05/13/arduino/"/>
    <id>http://example.com/2024/05/13/arduino/</id>
    <published>2024-05-13T13:33:01.323Z</published>
    <updated>2024-05-14T12:25:19.630Z</updated>
    
    
    
    
    
  </entry>
  
</feed>
